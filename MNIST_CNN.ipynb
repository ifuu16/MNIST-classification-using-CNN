{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f80a945b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cbea091",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the hyperparameters\n",
    "BUFFER_SIZE = 70_000\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fcf5380",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the dataset\n",
    "mnist_dataset, mnist_info = tfds.load(name='mnist', with_info = True, as_supervised=True)\n",
    "\n",
    "mnist_train, mnist_test = mnist_dataset['train'],  mnist_dataset['test']\n",
    "\n",
    "\n",
    "#Scaling the dataset. Fist cast the image to avoid value error\n",
    "def scale(image,label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 225.\n",
    "    \n",
    "    return image, label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3715952a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validation_data = mnist_train.map(scale)\n",
    "test_data = mnist_test.map(scale)\n",
    "\n",
    "#creating the number of validation dataset from the training dataset\n",
    "num_validation_samples = 0.1*mnist_info.splits['train'].num_examples\n",
    "\n",
    "#convert number of the validation sample to an integer to prevent potential issue\n",
    "num_validation_samples = tf.cast(num_validation_samples, tf.int64)\n",
    "\n",
    "#get the number data point in our  test samples\n",
    "num_test_samples = mnist_info.splits['test'].num_examples\n",
    "num_test_samples = tf.cast(num_test_samples, tf.int64)\n",
    "\n",
    "#Shuffle the training and validation dataset\n",
    "shuffle_train_and_validation_data = train_and_validation_data.shuffle(BUFFER_SIZE)\n",
    "\n",
    "\n",
    "#create the train data\n",
    "train_data = shuffle_train_and_validation_data.skip(num_validation_samples)\n",
    "\n",
    "#create the validation data\n",
    "validation_data = shuffle_train_and_validation_data.take(num_validation_samples)\n",
    "\n",
    "\n",
    "#batching the training data\n",
    "\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "\n",
    "#No need to batch the validation and test data(we are not backpropagating on them ). Hence we will take all at once]\n",
    "validation_data = validation_data.batch(num_validation_samples)\n",
    "\n",
    "test_data = test_data.batch(num_test_samples)\n",
    "\n",
    "validation_inputs, validation_targets = next(iter(validation_data))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35f4361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the model\n",
    "model = Sequential([\n",
    "        Conv2D(50, 5, activation= 'relu', input_shape=(28,28,1)),\n",
    "        MaxPooling2D(pool_size=(2,2)),\n",
    "        Conv2D(50, 3, activation= 'relu'),\n",
    "        MaxPooling2D(pool_size=(2,2)),\n",
    "        Flatten(),\n",
    "        Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d37cebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "___________________________________________________________________________\n",
      " Layer (type)                    Output Shape                  Param #     \n",
      "===========================================================================\n",
      " conv2d_2 (Conv2D)               (None, 24, 24, 50)            1300        \n",
      "                                                                           \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 50)            0           \n",
      "                                                                           \n",
      " conv2d_3 (Conv2D)               (None, 10, 10, 50)            22550       \n",
      "                                                                           \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 50)              0           \n",
      "                                                                           \n",
      " flatten_1 (Flatten)             (None, 1250)                  0           \n",
      "                                                                           \n",
      " dense_1 (Dense)                 (None, 10)                    12510       \n",
      "                                                                           \n",
      "===========================================================================\n",
      "Total params: 36,360\n",
      "Trainable params: 36,360\n",
      "Non-trainable params: 0\n",
      "___________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary(line_length=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f49cd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#describe the loss function\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "#COmpile the model\n",
    "\n",
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#Stop the model from overfitting ie whenever the validation loss increases\n",
    "#the code tells the model to stop when the val_loss starts to increase in two subsequent epics\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor= 'val_loss',\n",
    "    mode = 'auto',\n",
    "    min_delta = 0,\n",
    "    patience = 2,\n",
    "    verbose = 0,\n",
    "    restore_best_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "565cb469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "422/422 - 33s - loss: 0.2742 - accuracy: 0.9237 - val_loss: 0.0865 - val_accuracy: 0.9717 - 33s/epoch - 79ms/step\n",
      "Epoch 2/20\n",
      "422/422 - 31s - loss: 0.0753 - accuracy: 0.9769 - val_loss: 0.0581 - val_accuracy: 0.9847 - 31s/epoch - 74ms/step\n",
      "Epoch 3/20\n",
      "422/422 - 31s - loss: 0.0530 - accuracy: 0.9839 - val_loss: 0.0369 - val_accuracy: 0.9882 - 31s/epoch - 74ms/step\n",
      "Epoch 4/20\n",
      "422/422 - 34s - loss: 0.0432 - accuracy: 0.9870 - val_loss: 0.0301 - val_accuracy: 0.9898 - 34s/epoch - 79ms/step\n",
      "Epoch 5/20\n",
      "422/422 - 35s - loss: 0.0367 - accuracy: 0.9886 - val_loss: 0.0334 - val_accuracy: 0.9897 - 35s/epoch - 82ms/step\n",
      "Epoch 6/20\n",
      "422/422 - 36s - loss: 0.0313 - accuracy: 0.9904 - val_loss: 0.0256 - val_accuracy: 0.9912 - 36s/epoch - 86ms/step\n",
      "Epoch 7/20\n",
      "422/422 - 36s - loss: 0.0273 - accuracy: 0.9914 - val_loss: 0.0218 - val_accuracy: 0.9925 - 36s/epoch - 85ms/step\n",
      "Epoch 8/20\n",
      "422/422 - 36s - loss: 0.0240 - accuracy: 0.9925 - val_loss: 0.0204 - val_accuracy: 0.9917 - 36s/epoch - 86ms/step\n",
      "Epoch 9/20\n",
      "422/422 - 36s - loss: 0.0214 - accuracy: 0.9934 - val_loss: 0.0187 - val_accuracy: 0.9947 - 36s/epoch - 85ms/step\n",
      "Epoch 10/20\n",
      "422/422 - 37s - loss: 0.0184 - accuracy: 0.9940 - val_loss: 0.0146 - val_accuracy: 0.9968 - 37s/epoch - 87ms/step\n",
      "Epoch 11/20\n",
      "422/422 - 37s - loss: 0.0162 - accuracy: 0.9951 - val_loss: 0.0173 - val_accuracy: 0.9948 - 37s/epoch - 87ms/step\n",
      "Epoch 12/20\n",
      "422/422 - 43s - loss: 0.0141 - accuracy: 0.9957 - val_loss: 0.0075 - val_accuracy: 0.9980 - 43s/epoch - 103ms/step\n",
      "Epoch 13/20\n",
      "422/422 - 45s - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.0104 - val_accuracy: 0.9970 - 45s/epoch - 106ms/step\n",
      "Epoch 14/20\n",
      "422/422 - 44s - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.0095 - val_accuracy: 0.9960 - 44s/epoch - 104ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e7467fa5b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "model.fit(\n",
    "    train_data,\n",
    "    epochs = NUM_EPOCHS,\n",
    "    callbacks = [early_stopping],\n",
    "    validation_data = validation_data,\n",
    "    verbose =2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f4fd383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 0.0299 - accuracy: 0.9919\n",
      "Test Loss: 0.03. Test Accuracy:99.19%\n"
     ]
    }
   ],
   "source": [
    "#Test the model\n",
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "\n",
    "print(f'Test Loss: {round(test_loss,2)}. Test Accuracy:{round(test_accuracy*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80395c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the image and result\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
