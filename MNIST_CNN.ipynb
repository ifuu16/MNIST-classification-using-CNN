{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f80a945b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cbea091",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the hyperparameters\n",
    "BUFFER_SIZE = 70_000\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fcf5380",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the dataset\n",
    "mnist_dataset, mnist_info = tfds.load(name='mnist', with_info = True, as_supervised=True)\n",
    "\n",
    "mnist_train, mnist_test = mnist_dataset['train'],  mnist_dataset['test']\n",
    "\n",
    "\n",
    "#Scaling the dataset. Fist cast the image to avoid value error\n",
    "def scale(image,label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 225.\n",
    "    \n",
    "    return image, label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3715952a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validation_data = mnist_train.map(scale)\n",
    "test_data = mnist_test.map(scale)\n",
    "\n",
    "#creating the number of validation dataset from the training dataset\n",
    "num_validation_samples = 0.1*mnist_info.splits['train'].num_examples\n",
    "\n",
    "#convert number of the validation sample to an integer to prevent potential issue\n",
    "num_validation_samples = tf.cast(num_validation_samples, tf.int64)\n",
    "\n",
    "#get the number data point in our  test samples\n",
    "num_test_samples = mnist_info.splits['test'].num_examples\n",
    "num_test_samples = tf.cast(num_test_samples, tf.int64)\n",
    "\n",
    "#Shuffle the training and validation dataset\n",
    "shuffle_train_and_validation_data = train_and_validation_data.shuffle(BUFFER_SIZE)\n",
    "\n",
    "\n",
    "#create the train data\n",
    "train_data = shuffle_train_and_validation_data.skip(num_validation_samples)\n",
    "\n",
    "#create the validation data\n",
    "validation_data = shuffle_train_and_validation_data.take(num_validation_samples)\n",
    "\n",
    "\n",
    "#batching the training data\n",
    "\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "\n",
    "#No need to batch the validation and test data(we are not backpropagating on them ). Hence we will take all at once]\n",
    "validation_data = validation_data.batch(num_validation_samples)\n",
    "\n",
    "test_data = test_data.batch(num_test_samples)\n",
    "\n",
    "validation_inputs, validation_targets = next(iter(validation_data))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35f4361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the model\n",
    "model = Sequential([\n",
    "        Conv2D(50, 5, activation= 'relu', input_shape=(28,28,1)),\n",
    "        MaxPooling2D(pool_size=(2,2)),\n",
    "        Conv2D(50, 3, activation= 'relu'),\n",
    "        MaxPooling2D(pool_size=(2,2)),\n",
    "        Flatten(),\n",
    "        Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d37cebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "___________________________________________________________________________\n",
      " Layer (type)                    Output Shape                  Param #     \n",
      "===========================================================================\n",
      " conv2d_4 (Conv2D)               (None, 24, 24, 50)            1300        \n",
      "                                                                           \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 12, 12, 50)            0           \n",
      "                                                                           \n",
      " conv2d_5 (Conv2D)               (None, 10, 10, 50)            22550       \n",
      "                                                                           \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 5, 5, 50)              0           \n",
      "                                                                           \n",
      " flatten_2 (Flatten)             (None, 1250)                  0           \n",
      "                                                                           \n",
      " dense_2 (Dense)                 (None, 10)                    12510       \n",
      "                                                                           \n",
      "===========================================================================\n",
      "Total params: 36,360\n",
      "Trainable params: 36,360\n",
      "Non-trainable params: 0\n",
      "___________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary(line_length=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f49cd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#describe the loss function\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "#Compile the model\n",
    "\n",
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#Stop the model from overfitting ie whenever the validation loss increases\n",
    "#the code tells the model to stop when the val_loss starts to increase in two subsequent epics\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor= 'val_loss',\n",
    "    mode = 'auto',\n",
    "    min_delta = 0,\n",
    "    patience = 2,\n",
    "    verbose = 0,\n",
    "    restore_best_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8387846",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the current date and time as a string\n",
    "current_datetime = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "#Create a log directory based on the current date and time\n",
    "#log_dir = \"logs\\\\fit\\\\\"{current_datetime}\n",
    "log_dir = f'./logs/{current_datetime}'\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "565cb469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "422/422 - 36s - loss: 0.2662 - accuracy: 0.9245 - val_loss: 0.0823 - val_accuracy: 0.9745 - 36s/epoch - 86ms/step\n",
      "Epoch 2/20\n",
      "422/422 - 38s - loss: 0.0703 - accuracy: 0.9788 - val_loss: 0.0606 - val_accuracy: 0.9805 - 38s/epoch - 89ms/step\n",
      "Epoch 3/20\n",
      "422/422 - 35s - loss: 0.0526 - accuracy: 0.9839 - val_loss: 0.0406 - val_accuracy: 0.9867 - 35s/epoch - 82ms/step\n",
      "Epoch 4/20\n",
      "422/422 - 34s - loss: 0.0420 - accuracy: 0.9871 - val_loss: 0.0351 - val_accuracy: 0.9900 - 34s/epoch - 81ms/step\n",
      "Epoch 5/20\n",
      "422/422 - 35s - loss: 0.0363 - accuracy: 0.9889 - val_loss: 0.0335 - val_accuracy: 0.9897 - 35s/epoch - 83ms/step\n",
      "Epoch 6/20\n",
      "422/422 - 38s - loss: 0.0309 - accuracy: 0.9901 - val_loss: 0.0256 - val_accuracy: 0.9917 - 38s/epoch - 90ms/step\n",
      "Epoch 7/20\n",
      "422/422 - 40s - loss: 0.0277 - accuracy: 0.9914 - val_loss: 0.0234 - val_accuracy: 0.9923 - 40s/epoch - 95ms/step\n",
      "Epoch 8/20\n",
      "422/422 - 45s - loss: 0.0239 - accuracy: 0.9925 - val_loss: 0.0160 - val_accuracy: 0.9957 - 45s/epoch - 107ms/step\n",
      "Epoch 9/20\n",
      "422/422 - 51s - loss: 0.0199 - accuracy: 0.9939 - val_loss: 0.0156 - val_accuracy: 0.9950 - 51s/epoch - 122ms/step\n",
      "Epoch 10/20\n",
      "422/422 - 48s - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.0135 - val_accuracy: 0.9973 - 48s/epoch - 115ms/step\n",
      "Epoch 11/20\n",
      "422/422 - 46s - loss: 0.0158 - accuracy: 0.9949 - val_loss: 0.0130 - val_accuracy: 0.9958 - 46s/epoch - 110ms/step\n",
      "Epoch 12/20\n",
      "422/422 - 46s - loss: 0.0147 - accuracy: 0.9952 - val_loss: 0.0111 - val_accuracy: 0.9970 - 46s/epoch - 109ms/step\n",
      "Epoch 13/20\n",
      "422/422 - 46s - loss: 0.0129 - accuracy: 0.9958 - val_loss: 0.0087 - val_accuracy: 0.9968 - 46s/epoch - 108ms/step\n",
      "Epoch 14/20\n",
      "422/422 - 44s - loss: 0.0100 - accuracy: 0.9971 - val_loss: 0.0100 - val_accuracy: 0.9975 - 44s/epoch - 105ms/step\n",
      "Epoch 15/20\n",
      "422/422 - 44s - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.0098 - val_accuracy: 0.9972 - 44s/epoch - 105ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21706ae4430>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "model.fit(\n",
    "    train_data,\n",
    "    epochs = NUM_EPOCHS,\n",
    "    callbacks = [tensorboard_callback, early_stopping],\n",
    "    validation_data = validation_data,\n",
    "    verbose =2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f4fd383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0266 - accuracy: 0.9914\n",
      "Test Loss: 0.03. Test Accuracy:99.14%\n"
     ]
    }
   ],
   "source": [
    "#Test the model\n",
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "\n",
    "print(f'Test Loss: {round(test_loss,2)}. Test Accuracy:{round(test_accuracy*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9cccc936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#Plot the image and result\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Get and display the first n images from the training dataset. n=2\n",
    "num_images_to_display = 1\n",
    "for image, label in test_data.take(num_images_to_display):\n",
    "    sample_image = image.numpy()# Convert to numpy array and remove singleton dimensions\n",
    "    sample_label = label.numpy()\n",
    "\n",
    "original_images = sample_image.reshape(10000, 28, 28)\n",
    "\n",
    "# Display the image using matplotlib\n",
    "image_number_to_display = 8\n",
    "\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(sample_image[image_number_to_display], cmap='gray', aspect=\"auto\")\n",
    "plt.title(f'Label: {sample_label[image_number_to_display]}')\n",
    "plt.axis('off')  # Turn off axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd97b810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 102ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Obtain the model's prediction(logits)\n",
    "\n",
    "#Using slicing is important because tensorflow expects inputs to be in batches\n",
    "predictions = model.predict(sample_image[image_number_to_display:image_number_to_display+1])\n",
    "\n",
    "#Convert the predictions into probabilities and to percentage\n",
    "probabilities = (tf.nn.softmax(predictions).numpy()) *100\n",
    "\n",
    "#Create a bar chart to plot the probabilities for each class\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.bar(x=[1,2,3,4,5,6,7,8,9,10], height=probabilities[0], tick_label=[\"0\", \"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "956201a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f461d2879b0baf68\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f461d2879b0baf68\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#VIsualize the Tensorboard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./logs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534f5ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a90856",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
