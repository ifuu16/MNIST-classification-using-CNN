{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f80a945b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cbea091",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the hyperparameters\n",
    "BUFFER_SIZE = 70_000\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fcf5380",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the dataset\n",
    "mnist_dataset, mnist_info = tfds.load(name='mnist', with_info = True, as_supervised=True)\n",
    "\n",
    "mnist_train, mnist_test = mnist_dataset['train'],  mnist_dataset['test']\n",
    "\n",
    "\n",
    "#Scaling the dataset. Fist cast the image to avoid value error\n",
    "def scale(image,label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 225.\n",
    "    \n",
    "    return image, label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3715952a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validation_data = mnist_train.map(scale)\n",
    "test_data = mnist_test.map(scale)\n",
    "\n",
    "#creating the number of validation dataset from the training dataset\n",
    "num_validation_samples = 0.1*mnist_info.splits['train'].num_examples\n",
    "\n",
    "#convert number of the validation sample to an integer to prevent potential issue\n",
    "num_validation_samples = tf.cast(num_validation_samples, tf.int64)\n",
    "\n",
    "#get the number data point in our  test samples\n",
    "num_test_samples = mnist_info.splits['test'].num_examples\n",
    "num_test_samples = tf.cast(num_test_samples, tf.int64)\n",
    "\n",
    "#Shuffle the training and validation dataset\n",
    "shuffle_train_and_validation_data = train_and_validation_data.shuffle(BUFFER_SIZE)\n",
    "\n",
    "\n",
    "#create the train data\n",
    "train_data = shuffle_train_and_validation_data.skip(num_validation_samples)\n",
    "\n",
    "#create the validation data\n",
    "validation_data = shuffle_train_and_validation_data.take(num_validation_samples)\n",
    "\n",
    "\n",
    "#batching the training data\n",
    "\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "\n",
    "#No need to batch the validation and test data(we are not backpropagating on them ). Hence we will take all at once]\n",
    "validation_data = validation_data.batch(num_validation_samples)\n",
    "\n",
    "test_data = test_data.batch(num_test_samples)\n",
    "\n",
    "validation_inputs, validation_targets = next(iter(validation_data))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35f4361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the model\n",
    "model = Sequential([\n",
    "        Conv2D(50, 5, activation= 'relu', input_shape=(28,28,1)),\n",
    "        MaxPooling2D(pool_size=(2,2)),\n",
    "        Conv2D(50, 3, activation= 'relu'),\n",
    "        MaxPooling2D(pool_size=(2,2)),\n",
    "        Flatten(),\n",
    "        Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d37cebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "___________________________________________________________________________\n",
      " Layer (type)                    Output Shape                  Param #     \n",
      "===========================================================================\n",
      " conv2d (Conv2D)                 (None, 24, 24, 50)            1300        \n",
      "                                                                           \n",
      " max_pooling2d (MaxPooling2D)    (None, 12, 12, 50)            0           \n",
      "                                                                           \n",
      " conv2d_1 (Conv2D)               (None, 10, 10, 50)            22550       \n",
      "                                                                           \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 5, 5, 50)              0           \n",
      "                                                                           \n",
      " flatten (Flatten)               (None, 1250)                  0           \n",
      "                                                                           \n",
      " dense (Dense)                   (None, 10)                    12510       \n",
      "                                                                           \n",
      "===========================================================================\n",
      "Total params: 36,360\n",
      "Trainable params: 36,360\n",
      "Non-trainable params: 0\n",
      "___________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary(line_length=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f49cd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#describe the loss function\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "#Compile the model\n",
    "\n",
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#Stop the model from overfitting ie whenever the validation loss increases\n",
    "#the code tells the model to stop when the val_loss starts to increase in two subsequent epics\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor= 'val_loss',\n",
    "    mode = 'auto',\n",
    "    min_delta = 0,\n",
    "    patience = 2,\n",
    "    verbose = 0,\n",
    "    restore_best_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "565cb469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "422/422 - 35s - loss: 0.2663 - accuracy: 0.9225 - val_loss: 0.0729 - val_accuracy: 0.9773 - 35s/epoch - 82ms/step\n",
      "Epoch 2/20\n",
      "422/422 - 32s - loss: 0.0716 - accuracy: 0.9777 - val_loss: 0.0574 - val_accuracy: 0.9805 - 32s/epoch - 75ms/step\n",
      "Epoch 3/20\n",
      "422/422 - 31s - loss: 0.0526 - accuracy: 0.9837 - val_loss: 0.0441 - val_accuracy: 0.9862 - 31s/epoch - 74ms/step\n",
      "Epoch 4/20\n",
      "422/422 - 33s - loss: 0.0424 - accuracy: 0.9869 - val_loss: 0.0325 - val_accuracy: 0.9900 - 33s/epoch - 78ms/step\n",
      "Epoch 5/20\n",
      "422/422 - 33s - loss: 0.0365 - accuracy: 0.9887 - val_loss: 0.0322 - val_accuracy: 0.9912 - 33s/epoch - 79ms/step\n",
      "Epoch 6/20\n",
      "422/422 - 32s - loss: 0.0325 - accuracy: 0.9898 - val_loss: 0.0311 - val_accuracy: 0.9910 - 32s/epoch - 76ms/step\n",
      "Epoch 7/20\n",
      "422/422 - 32s - loss: 0.0265 - accuracy: 0.9916 - val_loss: 0.0186 - val_accuracy: 0.9942 - 32s/epoch - 76ms/step\n",
      "Epoch 8/20\n",
      "422/422 - 35s - loss: 0.0246 - accuracy: 0.9922 - val_loss: 0.0208 - val_accuracy: 0.9935 - 35s/epoch - 82ms/step\n",
      "Epoch 9/20\n",
      "422/422 - 35s - loss: 0.0203 - accuracy: 0.9934 - val_loss: 0.0212 - val_accuracy: 0.9927 - 35s/epoch - 82ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25e06ccf250>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "model.fit(\n",
    "    train_data,\n",
    "    epochs = NUM_EPOCHS,\n",
    "    callbacks = [early_stopping],\n",
    "    validation_data = validation_data,\n",
    "    verbose =2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f4fd383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 0.0295 - accuracy: 0.9897\n",
      "Test Loss: 0.03. Test Accuracy:98.97%\n"
     ]
    }
   ],
   "source": [
    "#Test the model\n",
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "\n",
    "print(f'Test Loss: {round(test_loss,2)}. Test Accuracy:{round(test_accuracy*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9cccc936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#Plot the image and result\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Get and display the first n images from the training dataset. n=2\n",
    "num_images_to_display = 1\n",
    "for image, label in test_data.take(num_images_to_display):\n",
    "    sample_image = image.numpy()# Convert to numpy array and remove singleton dimensions\n",
    "    sample_label = label.numpy()\n",
    "\n",
    "original_images = sample_image.reshape(10000, 28, 28)\n",
    "\n",
    "# Display the image using matplotlib\n",
    "image_number_to_display = 6\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(sample_image[image_number_to_display], cmap='gray', aspect=\"auto\")\n",
    "plt.title(f'Label: {sample_label[image_number_to_display]}')\n",
    "plt.axis('off')  # Turn off axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fd97b810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Obtain the model's prediction(logits)\n",
    "\n",
    "#Using slicing is important because tensorflow expects inputs to be in batches\n",
    "predictions = model.predict(sample_image[image_number_to_display:image_number_to_display+1])\n",
    "\n",
    "#Convert the predictions into probabilities and to percentage\n",
    "probabilities = (tf.nn.softmax(predictions).numpy()) *100\n",
    "\n",
    "#Create a bar chart to plot the probabilities for each class\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.bar(x=[1,2,3,4,5,6,7,8,9,10], height=probabilities[0], tick_label=[\"0\", \"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956201a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
